{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:31.299335Z",
     "iopub.status.busy": "2025-03-10T15:27:31.298723Z",
     "iopub.status.idle": "2025-03-10T15:27:33.541100Z",
     "shell.execute_reply": "2025-03-10T15:27:33.540261Z",
     "shell.execute_reply.started": "2025-03-10T15:27:31.299268Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import folium\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from shapely.geometry import Point, LineString\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing All Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:33.543619Z",
     "iopub.status.busy": "2025-03-10T15:27:33.542997Z",
     "iopub.status.idle": "2025-03-10T15:27:33.646947Z",
     "shell.execute_reply": "2025-03-10T15:27:33.645722Z",
     "shell.execute_reply.started": "2025-03-10T15:27:33.543579Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('dataset/public/train.csv')\n",
    "test_df = pd.read_csv(\"dataset/public/test.csv\")\n",
    "\n",
    "with open('dataset/public/routes.json') as f:\n",
    "    routes = json.load(f)\n",
    "with open('dataset/public/jalanraya_ui_flowcoord.json') as f:\n",
    "    flowcoord = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Infer Onerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:33.649098Z",
     "iopub.status.busy": "2025-03-10T15:27:33.648665Z",
     "iopub.status.idle": "2025-03-10T15:27:33.658868Z",
     "shell.execute_reply": "2025-03-10T15:27:33.657443Z",
     "shell.execute_reply.started": "2025-03-10T15:27:33.649052Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "def preprocess_json():\n",
    "    global routes, flowcoord, stops_data, track_data, color_to_route\n",
    "\n",
    "    color_to_route = {'red': 'RUTE_MERAH', 'blue': 'RUTE_BIRU'}\n",
    "\n",
    "    stops_data = {}\n",
    "    for route_name, stops in routes.items():\n",
    "        stop_names = list(stops.keys())\n",
    "        stop_coords = np.array(list(stops.values()))\n",
    "        stops_data[route_name] = {\n",
    "            'names': stop_names,\n",
    "            'coords': stop_coords\n",
    "        }\n",
    "\n",
    "    # Siapkan data koordinat jalur per rute (TRACK_RED, TRACK_BLUE)\n",
    "    track_data = {}\n",
    "    for track_name, points in flowcoord.items():\n",
    "        # Ambil list koordinat (lat, lon) dari masing-masing titik jalur\n",
    "        coords = np.array([(pt[\"latitude\"], pt[\"longitude\"]) for pt in points])\n",
    "        track_data[track_name] = coords\n",
    "\n",
    "    # Specify the new stop details\n",
    "    new_stop_key = \"tempat_turun_asrama\"\n",
    "    new_stop_coords = [-6.348499, 106.829623]\n",
    "\n",
    "    def insert_stop_before_target(route_dict, target_stop, new_key, new_coords):\n",
    "        new_route = OrderedDict()\n",
    "        for stop, coords in route_dict.items():\n",
    "            # When we reach the target, insert the new stop first\n",
    "            if stop == target_stop:\n",
    "                new_route[new_key] = new_coords\n",
    "            new_route[stop] = coords\n",
    "        return new_route\n",
    "\n",
    "    # Update both RUTE_MERAH and RUTE_BIRU by inserting the new stop before \"asrama_ui_01_end\"\n",
    "    for route_key in [\"RUTE_MERAH\", \"RUTE_BIRU\"]:\n",
    "        if route_key in routes:\n",
    "            routes[route_key] = insert_stop_before_target(routes[route_key], \"asrama_ui_01_end\", new_stop_key, new_stop_coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:33.660330Z",
     "iopub.status.busy": "2025-03-10T15:27:33.659972Z",
     "iopub.status.idle": "2025-03-10T15:27:33.682064Z",
     "shell.execute_reply": "2025-03-10T15:27:33.680843Z",
     "shell.execute_reply.started": "2025-03-10T15:27:33.660273Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def insert_stop_after_target_point(flow_list, target_lat, target_lon, new_stop_name, new_stop_coords):\n",
    "\n",
    "    updated_list = []\n",
    "    inserted = False\n",
    "    for idx, stop in enumerate(flow_list):\n",
    "        updated_list.append(stop)\n",
    "        if (abs(stop.get('latitude', 0) - target_lat) < 1e-6 and \n",
    "            abs(stop.get('longitude', 0) - target_lon) < 1e-6 and not inserted):\n",
    "            new_stop = {\n",
    "                \"name\": new_stop_name,\n",
    "                \"latitude\": new_stop_coords[0],\n",
    "                \"longitude\": new_stop_coords[1]\n",
    "            }\n",
    "            updated_list.append(new_stop)\n",
    "            inserted = True\n",
    "    if not inserted:\n",
    "        new_stop = {\n",
    "            \"name\": new_stop_name,\n",
    "            \"latitude\": new_stop_coords[0],\n",
    "            \"longitude\": new_stop_coords[1]\n",
    "        }\n",
    "        updated_list.append(new_stop)\n",
    "    return updated_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:33.683634Z",
     "iopub.status.busy": "2025-03-10T15:27:33.683210Z",
     "iopub.status.idle": "2025-03-10T15:27:33.702568Z",
     "shell.execute_reply": "2025-03-10T15:27:33.701404Z",
     "shell.execute_reply.started": "2025-03-10T15:27:33.683591Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def update_flowcoord_tracks():\n",
    "    global flowcoord, flowcoord_dict \n",
    "\n",
    "    target_lat = -6.3485456\n",
    "    target_lon = 106.8300938\n",
    "    new_stop_name = \"tempat_turun_asrama\"\n",
    "    new_stop_coords = (-6.348499, 106.829623)\n",
    "\n",
    "    for route_key in [\"TRACK_RED\", \"TRACK_BLUE\"]:\n",
    "        if route_key in flowcoord:\n",
    "            flowcoord[route_key] = insert_stop_after_target_point(\n",
    "                flowcoord[route_key], target_lat, target_lon, new_stop_name, new_stop_coords\n",
    "            )\n",
    "\n",
    "    flowcoord_dict = {\n",
    "            'red': flowcoord['TRACK_RED'],\n",
    "            'blue': flowcoord['TRACK_BLUE']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:33.704161Z",
     "iopub.status.busy": "2025-03-10T15:27:33.703743Z",
     "iopub.status.idle": "2025-03-10T15:27:33.721441Z",
     "shell.execute_reply": "2025-03-10T15:27:33.720334Z",
     "shell.execute_reply.started": "2025-03-10T15:27:33.704119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def update_nearest_halte(train_df, test_df):\n",
    "\n",
    "\n",
    "    train_df['halte_distance'] = np.nan     \n",
    "    test_df['halte_distance'] = np.nan\n",
    "\n",
    "    for color_val in ['red', 'blue']:\n",
    "        route_key = color_to_route[color_val]\n",
    "        stop_coords = stops_data[route_key]['coords']       \n",
    "        # Subset rows for the given color\n",
    "        mask = train_df['color'] == color_val\n",
    "        lat_points = train_df.loc[mask, 'lat'].to_numpy()\n",
    "        lon_points = train_df.loc[mask, 'lon'].to_numpy()\n",
    "        if lat_points.size == 0:\n",
    "            continue\n",
    "\n",
    "        lat_diff = lat_points[:, None] - stop_coords[:, 0][None, :]\n",
    "        lon_diff = lon_points[:, None] - stop_coords[:, 1][None, :]\n",
    "        cos_lat = np.cos(np.deg2rad(lat_points))\n",
    "        lat_diff_m = lat_diff * 111320.0\n",
    "        lon_diff_m = lon_diff * (111320.0 * cos_lat[:, None])\n",
    "        dist_sq = lat_diff_m**2 + lon_diff_m**2\n",
    "        min_dist = np.sqrt(np.min(dist_sq, axis=1))\n",
    "        train_df.loc[mask, 'halte_distance'] = min_dist\n",
    "\n",
    "    for color_val in ['red', 'blue']:\n",
    "        route_key = color_to_route[color_val]           \n",
    "        stop_coords = stops_data[route_key]['coords']\n",
    "        mask = test_df['color'] == color_val\n",
    "        lat_points = test_df.loc[mask, 'lat'].to_numpy()\n",
    "        lon_points = test_df.loc[mask, 'lon'].to_numpy()\n",
    "        if lat_points.size == 0:\n",
    "            continue\n",
    "\n",
    "        lat_diff = lat_points[:, None] - stop_coords[:, 0][None, :]\n",
    "        lon_diff = lon_points[:, None] - stop_coords[:, 1][None, :]\n",
    "        cos_lat = np.cos(np.deg2rad(lat_points))\n",
    "        lat_diff_m = lat_diff * 111320.0\n",
    "        lon_diff_m = lon_diff * (111320.0 * cos_lat[:, None])\n",
    "        dist_sq = lat_diff_m**2 + lon_diff_m**2\n",
    "        min_dist = np.sqrt(np.min(dist_sq, axis=1))\n",
    "        test_df.loc[mask, 'halte_distance'] = min_dist\n",
    "\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:33.724497Z",
     "iopub.status.busy": "2025-03-10T15:27:33.724122Z",
     "iopub.status.idle": "2025-03-10T15:27:33.745771Z",
     "shell.execute_reply": "2025-03-10T15:27:33.744482Z",
     "shell.execute_reply.started": "2025-03-10T15:27:33.724463Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def update_route_distance(train_df, test_df, track_data):\n",
    "    import numpy as np\n",
    "\n",
    "    train_df['route_distance'] = np.nan\n",
    "    test_df['route_distance'] = np.nan\n",
    "\n",
    "    for color_val in ['red', 'blue']:\n",
    "        track_key = 'TRACK_' + color_val.upper()         \n",
    "        track_coords = track_data[track_key]              \n",
    "        mask = train_df['color'] == color_val\n",
    "        lat_points = train_df.loc[mask, 'lat'].to_numpy()\n",
    "        lon_points = train_df.loc[mask, 'lon'].to_numpy()\n",
    "        if lat_points.size == 0:\n",
    "            continue\n",
    "\n",
    "        lat_diff = lat_points[:, None] - track_coords[:, 0][None, :]\n",
    "        lon_diff = lon_points[:, None] - track_coords[:, 1][None, :]\n",
    "        cos_lat = np.cos(np.deg2rad(lat_points))\n",
    "        lat_diff_m = lat_diff * 111320.0\n",
    "        lon_diff_m = lon_diff * (111320.0 * cos_lat[:, None])\n",
    "        dist_sq = lat_diff_m**2 + lon_diff_m**2\n",
    "        min_dist = np.sqrt(np.min(dist_sq, axis=1))  \n",
    "        train_df.loc[mask, 'route_distance'] = min_dist\n",
    "\n",
    "    for color_val in ['red', 'blue']:\n",
    "        track_key = 'TRACK_' + color_val.upper()          \n",
    "        track_coords = track_data[track_key]             \n",
    "        mask = test_df['color'] == color_val\n",
    "        lat_points = test_df.loc[mask, 'lat'].to_numpy()\n",
    "        lon_points = test_df.loc[mask, 'lon'].to_numpy()\n",
    "        if lat_points.size == 0:\n",
    "            continue\n",
    "\n",
    "        lat_diff = lat_points[:, None] - track_coords[:, 0][None, :]\n",
    "        lon_diff = lon_points[:, None] - track_coords[:, 1][None, :]\n",
    "        cos_lat = np.cos(np.deg2rad(lat_points))\n",
    "        lat_diff_m = lat_diff * 111320.0\n",
    "        lon_diff_m = lon_diff * (111320.0 * cos_lat[:, None])\n",
    "        dist_sq = lat_diff_m**2 + lon_diff_m**2\n",
    "        min_dist = np.sqrt(np.min(dist_sq, axis=1)) \n",
    "        test_df.loc[mask, 'route_distance'] = min_dist\n",
    "\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:33.747975Z",
     "iopub.status.busy": "2025-03-10T15:27:33.747650Z",
     "iopub.status.idle": "2025-03-10T15:27:33.769408Z",
     "shell.execute_reply": "2025-03-10T15:27:33.768348Z",
     "shell.execute_reply.started": "2025-03-10T15:27:33.747946Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000  # radius bumi dalam meter\n",
    "    phi1, phi2 = math.radians(lat1), math.radians(lat2)\n",
    "    d_phi = math.radians(lat2 - lat1)\n",
    "    d_lambda = math.radians(lon2 - lon1)\n",
    "    a = math.sin(d_phi / 2) ** 2 + math.cos(phi1) * math.cos(phi2) * math.sin(d_lambda / 2) ** 2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "# Fungsi mendapatkan titik terdekat pada jalur (flowcoord)\n",
    "def get_closest_point_on_route(lat, lon, flowcoord):\n",
    "    line = LineString([(pt[\"longitude\"], pt[\"latitude\"]) for pt in flowcoord])\n",
    "    point = Point(lon, lat)\n",
    "    proj_point = line.interpolate(line.project(point))\n",
    "    return proj_point.y, proj_point.x\n",
    "\n",
    "# Fungsi mendapatkan halte terdekat berdasarkan koordinat di flowcoord\n",
    "def get_nearest_stop_from_flowcoord(lat, lon, flowcoord):\n",
    "    min_distance = float('inf')\n",
    "    nearest_stop = None\n",
    "    for pt in flowcoord:\n",
    "        if pt[\"name\"]:  # hanya pertimbangkan titik dengan nama (halte)\n",
    "            stop_lat, stop_lon = pt[\"latitude\"], pt[\"longitude\"]\n",
    "            dist = haversine(lat, lon, stop_lat, stop_lon)\n",
    "            if dist < min_distance:\n",
    "                min_distance = dist\n",
    "                nearest_stop = pt[\"name\"]\n",
    "    return nearest_stop, min_distance\n",
    "\n",
    "# Fungsi utama menghitung halte dan jarak terdekat berbasis flowcoord\n",
    "def assign_nearest_stop_from_flowcoord(df, flowcoord_dict):\n",
    "    df = df.copy()\n",
    "    df['nearest_stop'] = None\n",
    "    df['distance_to_stop'] = np.nan\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        color = row['color'].lower()\n",
    "        flowcoord = flowcoord_dict[color]\n",
    "\n",
    "        # Dapatkan koordinat bus yang terproyeksi di rute flowcoord\n",
    "        proj_lat, proj_lon = get_closest_point_on_route(row['lat'], row['lon'], flowcoord)\n",
    "\n",
    "        # Dapatkan halte terdekat dari koordinat terproyeksi\n",
    "        nearest_stop, distance_to_stop = get_nearest_stop_from_flowcoord(proj_lat, proj_lon, flowcoord)\n",
    "\n",
    "        # Assign ke dataframe\n",
    "        df.at[idx, 'nearest_stop'] = nearest_stop\n",
    "        df.at[idx, 'distance_to_stop'] = distance_to_stop\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:33.770835Z",
     "iopub.status.busy": "2025-03-10T15:27:33.770522Z",
     "iopub.status.idle": "2025-03-10T15:27:33.791740Z",
     "shell.execute_reply": "2025-03-10T15:27:33.790588Z",
     "shell.execute_reply.started": "2025-03-10T15:27:33.770802Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def initialize_stop_columns(train_df, test_df):\n",
    "    import numpy as np\n",
    "    train_df['nearest_stop'] = None\n",
    "    train_df['distance_to_stop'] = np.nan\n",
    "    test_df['nearest_stop'] = None\n",
    "    test_df['distance_to_stop'] = np.nan\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:33.793031Z",
     "iopub.status.busy": "2025-03-10T15:27:33.792622Z",
     "iopub.status.idle": "2025-03-10T15:27:33.811402Z",
     "shell.execute_reply": "2025-03-10T15:27:33.810025Z",
     "shell.execute_reply.started": "2025-03-10T15:27:33.792988Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def convert_timestamps(train_df, test_df):\n",
    "    import pandas as pd\n",
    "    train_df['ts'] = pd.to_datetime(train_df['ts'])\n",
    "    test_df['ts'] = pd.to_datetime(test_df['ts'])\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:33.812925Z",
     "iopub.status.busy": "2025-03-10T15:27:33.812569Z",
     "iopub.status.idle": "2025-03-10T15:27:33.824751Z",
     "shell.execute_reply": "2025-03-10T15:27:33.823564Z",
     "shell.execute_reply.started": "2025-03-10T15:27:33.812895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def add_prev_next_stop_features(df, red_stops, blue_stops):\n",
    "\n",
    "    df = df.copy()\n",
    "    df['distance_to_prev_stop'] = np.nan\n",
    "    df['distance_to_next_stop'] = np.nan\n",
    "\n",
    "    def get_stop_index(nearest_stop, stops_list):\n",
    "        for idx, (stop_name, coords) in enumerate(stops_list):\n",
    "            if stop_name == nearest_stop:\n",
    "                return idx\n",
    "        return None\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        # Pilih list halte berdasarkan warna rute\n",
    "        stops_list = red_stops if row['color'] == 'red' else blue_stops\n",
    "        nearest_stop = row.get('nearest_stop')\n",
    "        if pd.isnull(nearest_stop) or nearest_stop is None:\n",
    "            continue\n",
    "        \n",
    "        idx_stop = get_stop_index(nearest_stop, stops_list)\n",
    "        if idx_stop is None:\n",
    "            continue\n",
    "\n",
    "        lat, lon = row['lat'], row['lon']\n",
    "        # Calculate distance to previous stop:\n",
    "        if idx_stop > 0:\n",
    "            prev_coords = stops_list[idx_stop - 1][1]\n",
    "        else:\n",
    "            # Wrap-around: if at the first stop, use the last stop as previous\n",
    "            prev_coords = stops_list[-1][1]\n",
    "        dist_prev = haversine(lat, lon, prev_coords[0], prev_coords[1])\n",
    "        df.at[idx, 'distance_to_prev_stop'] = dist_prev\n",
    "\n",
    "        # Calculate distance to next stop:\n",
    "        if idx_stop < len(stops_list) - 1:\n",
    "            next_coords = stops_list[idx_stop + 1][1]\n",
    "        else:\n",
    "            # Wrap-around: if at the last stop, use the first stop as next\n",
    "            next_coords = stops_list[0][1]\n",
    "        dist_next = haversine(lat, lon, next_coords[0], next_coords[1])\n",
    "        df.at[idx, 'distance_to_next_stop'] = dist_next\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:33.826189Z",
     "iopub.status.busy": "2025-03-10T15:27:33.825806Z",
     "iopub.status.idle": "2025-03-10T15:27:33.852719Z",
     "shell.execute_reply": "2025-03-10T15:27:33.851538Z",
     "shell.execute_reply.started": "2025-03-10T15:27:33.826150Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_time_diff(df, boole = False):\n",
    "\n",
    "    df = df.copy()\n",
    "    df['ts'] = pd.to_datetime(df['ts'])\n",
    "    df['time_diff'] = df['ts'].diff().dt.total_seconds()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:33.853998Z",
     "iopub.status.busy": "2025-03-10T15:27:33.853692Z",
     "iopub.status.idle": "2025-03-10T15:27:33.872449Z",
     "shell.execute_reply": "2025-03-10T15:27:33.871389Z",
     "shell.execute_reply.started": "2025-03-10T15:27:33.853970Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_rta(df):\n",
    "\n",
    "\n",
    "    df['tanggal'] = df['ts'].dt.date\n",
    "\n",
    "    def process_daily_group(daily_df):\n",
    "        marker_indices = []\n",
    "        current_halte = None\n",
    "        current_min_dist = None\n",
    "        current_min_idx = None\n",
    "\n",
    "        for i, row in daily_df.iterrows():\n",
    "            halte = row['nearest_stop']\n",
    "            dist = row['halte_distance']\n",
    "\n",
    "            if halte != current_halte:\n",
    "                if current_min_idx is not None:\n",
    "                    marker_indices.append(current_min_idx)\n",
    "\n",
    "                current_halte = halte\n",
    "                current_min_dist = dist\n",
    "                current_min_idx = i\n",
    "            else:\n",
    "                if dist < current_min_dist:\n",
    "                    current_min_dist = dist\n",
    "                    current_min_idx = i\n",
    "\n",
    "        if current_min_idx is not None:\n",
    "            marker_indices.append(current_min_idx)\n",
    "\n",
    "        def get_next_marker(idx):\n",
    "            for marker in marker_indices:\n",
    "                if marker > idx:\n",
    "                    return marker\n",
    "            return None\n",
    "\n",
    "        def compute_rta_row(row):\n",
    "            next_marker = get_next_marker(row.name)\n",
    "            if next_marker is not None:\n",
    "                return (daily_df.loc[next_marker, 'ts'] - row['ts']).total_seconds()\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        daily_df['rta'] = daily_df.apply(compute_rta_row, axis=1)\n",
    "\n",
    "        return daily_df\n",
    "\n",
    "    # Proses tiap hari secara terpisah\n",
    "    df = df.groupby('tanggal', group_keys=False).apply(process_daily_group).reset_index(drop=True)\n",
    "\n",
    "    df.drop(columns=['tanggal'], inplace=True)\n",
    "    df.drop(columns = [\"time_diff\"], inplace = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:33.873860Z",
     "iopub.status.busy": "2025-03-10T15:27:33.873499Z",
     "iopub.status.idle": "2025-03-10T15:27:33.898713Z",
     "shell.execute_reply": "2025-03-10T15:27:33.897430Z",
     "shell.execute_reply.started": "2025-03-10T15:27:33.873830Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def add_time_series_features(df, ts_column='ts'):\n",
    "\n",
    "    df[ts_column] = pd.to_datetime(df[ts_column])\n",
    "    \n",
    "    # Basic features (to be dropped later)\n",
    "    df['year'] = df[ts_column].dt.year\n",
    "    df['month'] = df[ts_column].dt.month\n",
    "    df['day'] = df[ts_column].dt.day\n",
    "    df['weekday'] = df[ts_column].dt.weekday\n",
    "    df['weekofyear'] = df[ts_column].dt.isocalendar().week.astype(int)\n",
    "    df['hour'] = df[ts_column].dt.hour\n",
    "    df['minute'] = df[ts_column].dt.minute\n",
    "    df['second'] = df[ts_column].dt.second\n",
    "    df['quarter'] = df[ts_column].dt.quarter\n",
    "\n",
    "    # Cyclical features\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "\n",
    "    df['minute_sin'] = np.sin(2 * np.pi * df['minute'] / 60)\n",
    "    df['minute_cos'] = np.cos(2 * np.pi * df['minute'] / 60)\n",
    "\n",
    "    df['second_sin'] = np.sin(2 * np.pi * df['second'] / 60)\n",
    "    df['second_cos'] = np.cos(2 * np.pi * df['second'] / 60)\n",
    "\n",
    "    df['weekday_sin'] = np.sin(2 * np.pi * df['weekday'] / 7)\n",
    "    df['weekday_cos'] = np.cos(2 * np.pi * df['weekday'] / 7)\n",
    "\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "\n",
    "    df['weekofyear_sin'] = np.sin(2 * np.pi * df['weekofyear'] / 52)\n",
    "    df['weekofyear_cos'] = np.cos(2 * np.pi * df['weekofyear'] / 52)\n",
    "    \n",
    "    basic_features = ['year', 'month', 'day', 'weekday', 'weekofyear', 'hour', 'minute', 'second', 'quarter']\n",
    "    df = df.drop(columns=basic_features)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:33.900192Z",
     "iopub.status.busy": "2025-03-10T15:27:33.899797Z",
     "iopub.status.idle": "2025-03-10T15:27:33.922745Z",
     "shell.execute_reply": "2025-03-10T15:27:33.921680Z",
     "shell.execute_reply.started": "2025-03-10T15:27:33.900161Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def has_passed_nearest_stop(row, flowcoord_dict):\n",
    "\n",
    "    # Tentukan rute berdasarkan kolom 'color' (misalnya 'red' atau 'blue')\n",
    "    route = row['color'].lower()\n",
    "    flowcoord_list = flowcoord_dict.get(route)\n",
    "    if flowcoord_list is None:\n",
    "        return np.nan  # Jika tidak ada data flowcoord, tidak bisa dihitung\n",
    "    \n",
    "    # Buat LineString dari flowcoord (ingat urutan (longitude, latitude))\n",
    "    line = LineString([(pt[\"longitude\"], pt[\"latitude\"]) for pt in flowcoord_list])\n",
    "    \n",
    "    # Cari titik marker halte sesuai 'nearest_stop'\n",
    "    marker = None\n",
    "    for pt in flowcoord_list:\n",
    "        if pt.get(\"name\") == row['nearest_stop']:\n",
    "            marker = pt\n",
    "            break\n",
    "    if marker is None:\n",
    "        return np.nan\n",
    "    \n",
    "    stop_point = Point(marker[\"longitude\"], marker[\"latitude\"])\n",
    "    bus_point = Point(row['lon'], row['lat'])\n",
    "    \n",
    "    stop_proj = line.project(stop_point)\n",
    "    bus_proj = line.project(bus_point)\n",
    "    \n",
    "    # Jika bus_proj >= stop_proj, artinya bus sudah melewati (atau tepat di titik) marker halte\n",
    "    return bus_proj >= stop_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:33.924189Z",
     "iopub.status.busy": "2025-03-10T15:27:33.923826Z",
     "iopub.status.idle": "2025-03-10T15:27:33.946575Z",
     "shell.execute_reply": "2025-03-10T15:27:33.944937Z",
     "shell.execute_reply.started": "2025-03-10T15:27:33.924148Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def separate_outside_and_short_route(df, flowcoord_dict, start_stop='tempat_turun_asrama', end_stop='asrama_ui_01_end'):\n",
    "    df = df.copy()\n",
    "\n",
    "    full_routes = {}\n",
    "    short_routes = {}\n",
    "\n",
    "    for color, coords in flowcoord_dict.items():\n",
    "        line_full = LineString([(pt['longitude'], pt['latitude']) for pt in coords])\n",
    "        full_routes[color] = line_full\n",
    "\n",
    "        start_idx, end_idx = None, None\n",
    "        for i, pt in enumerate(coords):\n",
    "            if pt['name'] == start_stop:\n",
    "                start_idx = i\n",
    "            elif pt['name'] == end_stop:\n",
    "                end_idx = i\n",
    "                break\n",
    "\n",
    "        if start_idx is not None and end_idx is not None and start_idx < end_idx:\n",
    "            short_route_coords = coords[start_idx:end_idx + 1]\n",
    "        else:\n",
    "            short_route_coords = coords[end_idx:start_idx + 1]\n",
    "\n",
    "        line_short = LineString([(pt['longitude'], pt['latitude']) for pt in short_route_coords])\n",
    "        short_routes[color] = line_short\n",
    "\n",
    "    # Pisahkan data\n",
    "    outside_flowcoord = []\n",
    "    short_route_data = []\n",
    "    normal_route_data = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        bus_point = Point(row['lon'], row['lat'])\n",
    "        color = row['color'].lower()\n",
    "\n",
    "        dist_to_full_route = bus_point.distance(full_routes[color])\n",
    "\n",
    "        # Threshold (misalnya, 50 meter dari jalur utama dianggap di luar jalur)\n",
    "        if dist_to_full_route > 0.0005:  # ~50m dalam derajat\n",
    "            outside_flowcoord.append(idx)\n",
    "            continue\n",
    "\n",
    "        # Cek apakah di jalur pendek khusus\n",
    "        dist_to_short_route = bus_point.distance(short_routes[color])\n",
    "\n",
    "        if dist_to_short_route <= 0.0005:\n",
    "            short_route_data.append(idx)\n",
    "        else:\n",
    "            normal_route_data.append(idx)\n",
    "\n",
    "    df_outside_flowcoord = df.loc[outside_flowcoord]\n",
    "    df_short_route = df.loc[short_route_data]\n",
    "    df_normal_route = df.loc[normal_route_data]\n",
    "\n",
    "    return df_outside_flowcoord, df_short_route, df_normal_route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:33.948248Z",
     "iopub.status.busy": "2025-03-10T15:27:33.947824Z",
     "iopub.status.idle": "2025-03-10T15:27:33.973092Z",
     "shell.execute_reply": "2025-03-10T15:27:33.971703Z",
     "shell.execute_reply.started": "2025-03-10T15:27:33.948203Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def filter_train_data(df_normal, df_short_route, df_outside):\n",
    "    train_df_normal = df_normal[\n",
    "        (df_normal['rta'] >= 0) & (df_normal['rta'] <= 500) &\n",
    "        (df_normal['speed'] >= 0) & (df_normal['speed'] <= 100)\n",
    "    ].copy()\n",
    "\n",
    "    train_df_short_route = df_short_route[\n",
    "        (df_short_route['rta'] >= 0) &\n",
    "        (df_short_route['speed'] >= 0) & (df_short_route['speed'] <= 100)\n",
    "    ].copy()\n",
    "\n",
    "    train_df_outside = df_outside[\n",
    "        (df_outside['rta'] >= 0) &\n",
    "        (df_outside['speed'] >= 0) & (df_outside['speed'] <= 100)\n",
    "    ].copy()\n",
    "\n",
    "    return train_df_normal, train_df_short_route, train_df_outside\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:33.974730Z",
     "iopub.status.busy": "2025-03-10T15:27:33.974385Z",
     "iopub.status.idle": "2025-03-10T15:27:33.996054Z",
     "shell.execute_reply": "2025-03-10T15:27:33.995027Z",
     "shell.execute_reply.started": "2025-03-10T15:27:33.974698Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def cut_excess_same_group_speed_zero(\n",
    "    df,\n",
    "    group_cols = [\n",
    "        'speed',\n",
    "        'halte_distance',\n",
    "        'route_distance',\n",
    "        'nearest_stop',\n",
    "        'distance_to_stop',\n",
    "        'distance_to_prev_stop',\n",
    "        'distance_to_next_stop'\n",
    "    ],\n",
    "    max_rows=2\n",
    "):\n",
    "    \"\"\"\n",
    "    Groups rows by the specified group_cols. If speed=0 and a group has more than `max_rows` rows,\n",
    "    keep only the `max_rows` rows with the lowest rta and drop the rest.\n",
    "    \n",
    "    Returns:\n",
    "      df_filtered: The filtered DfataFrame.\n",
    "      dropped_count: How many rows were removed in total.\n",
    "    \"\"\"\n",
    "\n",
    "    df_speed_zero = df[df['speed'] == 0].copy()\n",
    "    df_not_zero = df[df['speed'] != 0]\n",
    "\n",
    "    filtered_groups = []\n",
    "\n",
    "    grouped = df_speed_zero.groupby(group_cols, dropna=False)  \n",
    "\n",
    "    for group_key, group_df in grouped:\n",
    "        if len(group_df) > max_rows:\n",
    "            group_df = group_df.sort_values('rta', ascending=True).head(max_rows)\n",
    "        filtered_groups.append(group_df)\n",
    "\n",
    "    df_speed_zero_filtered = pd.concat(filtered_groups, ignore_index=True)\n",
    "\n",
    "    df_filtered = pd.concat([df_not_zero, df_speed_zero_filtered], ignore_index=True)\n",
    "\n",
    "    dropped_count = len(df) - len(df_filtered)\n",
    "\n",
    "    return df_filtered, dropped_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:33.997478Z",
     "iopub.status.busy": "2025-03-10T15:27:33.997124Z",
     "iopub.status.idle": "2025-03-10T15:27:34.013574Z",
     "shell.execute_reply": "2025-03-10T15:27:34.012560Z",
     "shell.execute_reply.started": "2025-03-10T15:27:33.997434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(df, column, factor=1.5):\n",
    "\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - factor * IQR\n",
    "    upper_bound = Q3 + factor * IQR\n",
    "    filtered_df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)].copy()\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:34.015048Z",
     "iopub.status.busy": "2025-03-10T15:27:34.014704Z",
     "iopub.status.idle": "2025-03-10T15:27:34.039792Z",
     "shell.execute_reply": "2025-03-10T15:27:34.038519Z",
     "shell.execute_reply.started": "2025-03-10T15:27:34.015016Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load and define stops and flowcoord dictionary\n",
    "\n",
    "red_stops = list(routes[\"RUTE_MERAH\"].items())\n",
    "blue_stops = list(routes[\"RUTE_BIRU\"].items())\n",
    "\n",
    "def process(train_df, test_df):\n",
    "    \n",
    "    preprocess_json()\n",
    "    update_flowcoord_tracks()\n",
    "    train_df, test_df = convert_timestamps(train_df, test_df)\n",
    "    train_df, test_df = update_nearest_halte(train_df, test_df)\n",
    "    train_df, test_df = update_route_distance(train_df, test_df, track_data)\n",
    "    train_df, test_df = initialize_stop_columns(train_df, test_df)\n",
    "    train_df = assign_nearest_stop_from_flowcoord(train_df, flowcoord_dict)\n",
    "    test_df = assign_nearest_stop_from_flowcoord(test_df, flowcoord_dict)\n",
    "    test_df = add_prev_next_stop_features(test_df, red_stops, blue_stops)\n",
    "    train_df = add_prev_next_stop_features(train_df, red_stops, blue_stops)\n",
    "    train_df = compute_time_diff(train_df)\n",
    "    train_df = compute_rta(train_df)\n",
    "    train_df = add_time_series_features(train_df)\n",
    "    test_df = add_time_series_features(test_df)\n",
    "    train_df['passed_stop'] = train_df.apply(lambda row: has_passed_nearest_stop(row, flowcoord_dict), axis=1)\n",
    "    test_df['passed_stop'] = test_df.apply(lambda row: has_passed_nearest_stop(row, flowcoord_dict), axis=1)\n",
    "    \n",
    "    df_outside, df_short_route, df_normal = separate_outside_and_short_route(train_df, flowcoord_dict)\n",
    "    \n",
    "    train_df_normal, train_df_short_route, train_df_outside = filter_train_data(df_normal, df_short_route, df_outside)\n",
    "    \n",
    "    train_df_normal, dropped_count = cut_excess_same_group_speed_zero(train_df_normal)\n",
    "    train_df_short_route, dropped_count2 = cut_excess_same_group_speed_zero(train_df_short_route)\n",
    "    train_df_outside, dropped_count3 = cut_excess_same_group_speed_zero(train_df_outside)\n",
    "    \n",
    "    train_df_normal_clean = remove_outliers_iqr(train_df_normal, 'rta', factor=1.5)\n",
    "    train_df_short_route_clean = remove_outliers_iqr(train_df_short_route, 'rta', factor=1.5)\n",
    "    train_df_outside_clean = remove_outliers_iqr(train_df_outside, 'rta', factor=1.5)\n",
    "    \n",
    "    test_outside, test_short_route, test_normal = separate_outside_and_short_route(test_df, flowcoord_dict)\n",
    "    \n",
    "    print(f\"Number of rows dropped: {dropped_count} {dropped_count2} {dropped_count3}\")\n",
    "    print(\"Normal group shape before:\", df_normal.shape, \"after:\", train_df_normal_clean.shape)\n",
    "    print(\"Short route group shape before:\", df_short_route.shape, \"after:\", train_df_short_route_clean.shape)\n",
    "    print(\"Outside group shape before:\", df_outside.shape, \"after:\", train_df_outside_clean.shape)\n",
    "    \n",
    "    return {\n",
    "        'train_df_normal_clean': train_df_normal_clean,\n",
    "        'train_df_short_route_clean': train_df_short_route_clean,\n",
    "        'train_df_outside_clean': train_df_outside_clean,\n",
    "        'test_normal': test_normal,\n",
    "        'test_short_route': test_short_route,\n",
    "        'test_outside': test_outside,\n",
    "        'train_df': train_df, \n",
    "        'test_df': test_df \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:34.041351Z",
     "iopub.status.busy": "2025-03-10T15:27:34.040968Z",
     "iopub.status.idle": "2025-03-10T15:27:34.066974Z",
     "shell.execute_reply": "2025-03-10T15:27:34.065872Z",
     "shell.execute_reply.started": "2025-03-10T15:27:34.041313Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_models_with_best_params(train_processed, best_params, \n",
    "                                  cat_features=['color', 'nearest_stop', 'passed_stop'], \n",
    "                                  exclude_cols=['rta', 'imei', 'ts']):\n",
    "\n",
    "    # Build feature lists by dropping the excluded columns.\n",
    "    features_normal = [col for col in train_processed['df_normal'].columns if col not in exclude_cols]\n",
    "    features_short  = [col for col in train_processed['df_short_route'].columns if col not in exclude_cols]\n",
    "    features_outside = [col for col in train_processed['df_outside'].columns if col not in exclude_cols]\n",
    "    \n",
    "    # Extract training features and target for each group.\n",
    "    X_normal = train_processed['df_normal'][features_normal]\n",
    "    y_normal = train_processed['df_normal']['rta']\n",
    "    \n",
    "    X_short = train_processed['df_short_route'][features_short]\n",
    "    y_short = train_processed['df_short_route']['rta']\n",
    "    \n",
    "    X_outside = train_processed['df_outside'][features_outside]\n",
    "    y_outside = train_processed['df_outside']['rta']\n",
    "    \n",
    "    # Instantiate models using the best parameters.\n",
    "    model_normal = CatBoostRegressor(**best_params['normal'], random_seed=42, verbose=100, cat_features=cat_features)\n",
    "    model_short  = CatBoostRegressor(**best_params['short'], random_seed=42, verbose=100, cat_features=cat_features)\n",
    "    model_outside = CatBoostRegressor(**best_params['outside'], random_seed=42, verbose=100, cat_features=cat_features)\n",
    "    \n",
    "    # Train the models.\n",
    "    model_normal.fit(X_normal, y_normal)\n",
    "    model_short.fit(X_short, y_short)\n",
    "    model_outside.fit(X_outside, y_outside)\n",
    "    \n",
    "    models = {\n",
    "        'normal': model_normal,\n",
    "        'short': model_short,\n",
    "        'outside': model_outside\n",
    "    }\n",
    "    \n",
    "    feature_lists = {\n",
    "        'features_normal': features_normal,\n",
    "        'features_short': features_short,\n",
    "        'features_outside': features_outside\n",
    "    }\n",
    "    \n",
    "    return models, feature_lists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:34.071335Z",
     "iopub.status.busy": "2025-03-10T15:27:34.070919Z",
     "iopub.status.idle": "2025-03-10T15:27:34.089715Z",
     "shell.execute_reply": "2025-03-10T15:27:34.088621Z",
     "shell.execute_reply.started": "2025-03-10T15:27:34.071273Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def infer(models, train_processed, test_processed):\n",
    "    \n",
    "    exclude_cols = ['rta', 'imei', 'ts']\n",
    "    \n",
    "   \n",
    "    features_normal = [col for col in train_processed['df_normal'].columns if col not in exclude_cols]\n",
    "    features_short  = [col for col in train_processed['df_short_route'].columns if col not in exclude_cols]\n",
    "    features_outside = [col for col in train_processed['df_outside'].columns if col not in exclude_cols]\n",
    "    \n",
    "    test_normal = test_processed['test_normal'].copy()\n",
    "    test_short  = test_processed['test_short_route'].copy()\n",
    "    test_outside = test_processed['test_outside'].copy()\n",
    "    \n",
    "    test_normal['predicted_rta'] = models['normal'].predict(test_normal[features_normal])\n",
    "    test_short['predicted_rta']  = models['short'].predict(test_short[features_short])\n",
    "    test_outside['predicted_rta'] = models['outside'].predict(test_outside[features_outside])\n",
    "    \n",
    "    final_predictions = pd.concat([test_normal, test_short, test_outside])\n",
    "    \n",
    "    if 'Id' in final_predictions.columns:\n",
    "        final_predictions = final_predictions.sort_values(by='Id').reset_index(drop=True)\n",
    "    else:\n",
    "        final_predictions = final_predictions.sort_values(by='ts').reset_index(drop=True)\n",
    "    \n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:27:34.091487Z",
     "iopub.status.busy": "2025-03-10T15:27:34.091028Z",
     "iopub.status.idle": "2025-03-10T15:29:19.715050Z",
     "shell.execute_reply": "2025-03-10T15:29:19.713818Z",
     "shell.execute_reply.started": "2025-03-10T15:27:34.091447Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/shapely/linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "/usr/local/lib/python3.10/dist-packages/shapely/linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "<ipython-input-14-855c140607dd>:49: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('tanggal', group_keys=False).apply(process_daily_group).reset_index(drop=True)\n",
      "/usr/local/lib/python3.10/dist-packages/shapely/linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "/usr/local/lib/python3.10/dist-packages/shapely/linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows dropped: 3033 1619 64\n",
      "Normal group shape before: (31546, 26) after: (26481, 26)\n",
      "Short route group shape before: (3913, 26) after: (1964, 26)\n",
      "Outside group shape before: (1932, 26) after: (1740, 26)\n",
      "0:\tlearn: 40.9240169\ttotal: 83ms\tremaining: 28.1s\n",
      "100:\tlearn: 30.4812549\ttotal: 2.11s\tremaining: 4.99s\n",
      "200:\tlearn: 28.5721727\ttotal: 4.13s\tremaining: 2.85s\n",
      "300:\tlearn: 27.2506107\ttotal: 6.15s\tremaining: 796ms\n",
      "339:\tlearn: 26.7957360\ttotal: 6.93s\tremaining: 0us\n",
      "0:\tlearn: 204.8756719\ttotal: 3.87ms\tremaining: 878ms\n",
      "100:\tlearn: 138.9068231\ttotal: 346ms\tremaining: 435ms\n",
      "200:\tlearn: 111.4974365\ttotal: 683ms\tremaining: 91.7ms\n",
      "227:\tlearn: 103.4295062\ttotal: 774ms\tremaining: 0us\n",
      "0:\tlearn: 542.4551083\ttotal: 1.14ms\tremaining: 499ms\n",
      "100:\tlearn: 490.8896737\ttotal: 96.1ms\tremaining: 320ms\n",
      "200:\tlearn: 468.9735099\ttotal: 192ms\tremaining: 225ms\n",
      "300:\tlearn: 453.3088032\ttotal: 284ms\tremaining: 128ms\n",
      "400:\tlearn: 440.7996502\ttotal: 379ms\tremaining: 34ms\n",
      "436:\tlearn: 437.1802978\ttotal: 413ms\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "processed = process(train_df, test_df)\n",
    "\n",
    "train_processed = {\n",
    "    'df_normal': processed['train_df_normal_clean'],\n",
    "    'df_short_route': processed['train_df_short_route_clean'],\n",
    "    'df_outside': processed['train_df_outside_clean']\n",
    "}\n",
    "test_processed = {\n",
    "    'test_normal': processed['test_normal'],\n",
    "    'test_short_route': processed['test_short_route'],\n",
    "    'test_outside': processed['test_outside']\n",
    "}\n",
    "best_params = {\n",
    "    'normal': {'iterations': 340, 'learning_rate': 0.027188679538070405, 'depth': 9, 'l2_leaf_reg': 0.23646292318575496},\n",
    "    'short': {'iterations': 228, 'learning_rate': 0.04144306103458824, 'depth': 7, 'l2_leaf_reg': 0.07322510407071876},\n",
    "    'outside': {'iterations': 437, 'learning_rate': 0.011719382854506731, 'depth': 3, 'l2_leaf_reg': 0.005793040960392915}\n",
    "}\n",
    "\n",
    "models, feature_lists = build_models_with_best_params(train_processed, best_params)\n",
    "\n",
    "\n",
    "final_predictions = infer(models, train_processed, test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:29:19.716395Z",
     "iopub.status.busy": "2025-03-10T15:29:19.716079Z",
     "iopub.status.idle": "2025-03-10T15:29:20.980842Z",
     "shell.execute_reply": "2025-03-10T15:29:20.979556Z",
     "shell.execute_reply.started": "2025-03-10T15:29:19.716366Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for key, df in train_processed.items():\n",
    "    df.to_csv(f\"{key}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:29:20.982213Z",
     "iopub.status.busy": "2025-03-10T15:29:20.981829Z",
     "iopub.status.idle": "2025-03-10T15:29:21.003733Z",
     "shell.execute_reply": "2025-03-10T15:29:21.002575Z",
     "shell.execute_reply.started": "2025-03-10T15:29:20.982173Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission preview:\n",
      "   id        rta\n",
      "0   0  93.576518\n",
      "1   1  93.549229\n",
      "2   2  96.431483\n",
      "3   3  61.459277\n",
      "4   4  84.960969\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'id': final_predictions['Id'],  # ensure this column exists in your test data\n",
    "    'rta': final_predictions['predicted_rta']\n",
    "})\n",
    "\n",
    "# Clip any negative values to 0\n",
    "submission['rta'] = submission['rta'].clip(lower=0)\n",
    "\n",
    "submission.to_csv(\"submission_pake_3model_highest_outlierremove_tuned.csv\", index=False)\n",
    "print(\"Submission preview:\")\n",
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:29:21.005164Z",
     "iopub.status.busy": "2025-03-10T15:29:21.004784Z",
     "iopub.status.idle": "2025-03-10T15:29:21.300798Z",
     "shell.execute_reply": "2025-03-10T15:29:21.299657Z",
     "shell.execute_reply.started": "2025-03-10T15:29:21.005129Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-d95482ead8d4>:2: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import pkg_resources\n",
    "\n",
    "installed_packages = {pkg.key for pkg in pkg_resources.working_set}\n",
    "\n",
    "# Menyimpan nama library beserta versi yang digunakan ke file requirements.txt\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    for package in sorted(installed_packages):\n",
    "        version = pkg_resources.get_distribution(package).version\n",
    "        f.write(f\"{package}=={version}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11198557,
     "sourceId": 94040,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
