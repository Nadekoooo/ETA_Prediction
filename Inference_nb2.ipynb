{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:54.364809Z",
     "iopub.status.busy": "2025-03-10T16:07:54.364394Z",
     "iopub.status.idle": "2025-03-10T16:07:56.483651Z",
     "shell.execute_reply": "2025-03-10T16:07:56.482517Z",
     "shell.execute_reply.started": "2025-03-10T16:07:54.364781Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import folium\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from shapely.geometry import Point, LineString\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing All Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:56.486518Z",
     "iopub.status.busy": "2025-03-10T16:07:56.486018Z",
     "iopub.status.idle": "2025-03-10T16:07:56.597414Z",
     "shell.execute_reply": "2025-03-10T16:07:56.596352Z",
     "shell.execute_reply.started": "2025-03-10T16:07:56.486488Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('dataset/public/train.csv')\n",
    "test_df = pd.read_csv(\"dataset/public/test.csv\")\n",
    "\n",
    "with open('dataset/public/routes.json') as f:\n",
    "    routes = json.load(f)\n",
    "with open('dataset/public/jalanraya_ui_flowcoord.json') as f:\n",
    "    flowcoord = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Infer Onerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:56.599228Z",
     "iopub.status.busy": "2025-03-10T16:07:56.598861Z",
     "iopub.status.idle": "2025-03-10T16:07:56.607434Z",
     "shell.execute_reply": "2025-03-10T16:07:56.606164Z",
     "shell.execute_reply.started": "2025-03-10T16:07:56.599188Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "def preprocess_json():\n",
    "    global routes, flowcoord, stops_data, track_data, color_to_route\n",
    "\n",
    "    # Assume routes and flowcoord have already been loaded externally.\n",
    "    # Mapping warna ke key rute pada JSON\n",
    "    color_to_route = {'red': 'RUTE_MERAH', 'blue': 'RUTE_BIRU'}\n",
    "\n",
    "    # Siapkan data halte per rute: nama-nama halte dan array koordinat\n",
    "    stops_data = {}\n",
    "    for route_name, stops in routes.items():\n",
    "        stop_names = list(stops.keys())\n",
    "        stop_coords = np.array(list(stops.values()))  # array Nx2: [lat, lon] untuk setiap halte\n",
    "        stops_data[route_name] = {\n",
    "            'names': stop_names,\n",
    "            'coords': stop_coords\n",
    "        }\n",
    "\n",
    "    # Siapkan data koordinat jalur per rute (TRACK_RED, TRACK_BLUE)\n",
    "    track_data = {}\n",
    "    for track_name, points in flowcoord.items():\n",
    "        # Ambil list koordinat (lat, lon) dari masing-masing titik jalur\n",
    "        coords = np.array([(pt[\"latitude\"], pt[\"longitude\"]) for pt in points])\n",
    "        track_data[track_name] = coords\n",
    "\n",
    "    # Specify the new stop details\n",
    "    new_stop_key = \"tempat_turun_asrama\"\n",
    "    new_stop_coords = [-6.348499, 106.829623]\n",
    "\n",
    "    def insert_stop_before_target(route_dict, target_stop, new_key, new_coords):\n",
    "        new_route = OrderedDict()\n",
    "        for stop, coords in route_dict.items():\n",
    "            # When we reach the target, insert the new stop first\n",
    "            if stop == target_stop:\n",
    "                new_route[new_key] = new_coords\n",
    "            new_route[stop] = coords\n",
    "        return new_route\n",
    "\n",
    "    # Update both RUTE_MERAH and RUTE_BIRU by inserting the new stop before \"asrama_ui_01_end\"\n",
    "    for route_key in [\"RUTE_MERAH\", \"RUTE_BIRU\"]:\n",
    "        if route_key in routes:\n",
    "            routes[route_key] = insert_stop_before_target(routes[route_key], \"asrama_ui_01_end\", new_stop_key, new_stop_coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:56.608970Z",
     "iopub.status.busy": "2025-03-10T16:07:56.608623Z",
     "iopub.status.idle": "2025-03-10T16:07:56.631667Z",
     "shell.execute_reply": "2025-03-10T16:07:56.630495Z",
     "shell.execute_reply.started": "2025-03-10T16:07:56.608941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def insert_stop_after_target_point(flow_list, target_lat, target_lon, new_stop_name, new_stop_coords):\n",
    "\n",
    "    updated_list = []\n",
    "    inserted = False\n",
    "    for idx, stop in enumerate(flow_list):\n",
    "        updated_list.append(stop)\n",
    "        # Check if this stop matches the target (using a tolerance if needed)\n",
    "        if (abs(stop.get('latitude', 0) - target_lat) < 1e-6 and \n",
    "            abs(stop.get('longitude', 0) - target_lon) < 1e-6 and not inserted):\n",
    "            # Insert the new stop immediately after this one.\n",
    "            new_stop = {\n",
    "                \"name\": new_stop_name,\n",
    "                \"latitude\": new_stop_coords[0],\n",
    "                \"longitude\": new_stop_coords[1]\n",
    "            }\n",
    "            updated_list.append(new_stop)\n",
    "            inserted = True\n",
    "\n",
    "    if not inserted:\n",
    "        new_stop = {\n",
    "            \"name\": new_stop_name,\n",
    "            \"latitude\": new_stop_coords[0],\n",
    "            \"longitude\": new_stop_coords[1]\n",
    "        }\n",
    "        updated_list.append(new_stop)\n",
    "    return updated_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:56.633269Z",
     "iopub.status.busy": "2025-03-10T16:07:56.632878Z",
     "iopub.status.idle": "2025-03-10T16:07:56.656409Z",
     "shell.execute_reply": "2025-03-10T16:07:56.655395Z",
     "shell.execute_reply.started": "2025-03-10T16:07:56.633230Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def update_flowcoord_tracks():\n",
    "    global flowcoord, flowcoord_dict  # this global variable will be affected by the function\n",
    "\n",
    "    # Set target coordinates to look for and new stop details\n",
    "    target_lat = -6.3485456\n",
    "    target_lon = 106.8300938\n",
    "    new_stop_name = \"tempat_turun_asrama\"\n",
    "    new_stop_coords = (-6.348499, 106.829623)\n",
    "\n",
    "    # For both TRACK_RED and TRACK_BLUE, update the list\n",
    "    for route_key in [\"TRACK_RED\", \"TRACK_BLUE\"]:\n",
    "        if route_key in flowcoord:\n",
    "            flowcoord[route_key] = insert_stop_after_target_point(\n",
    "                flowcoord[route_key], target_lat, target_lon, new_stop_name, new_stop_coords\n",
    "            )\n",
    "\n",
    "    flowcoord_dict = {\n",
    "            'red': flowcoord['TRACK_RED'],\n",
    "            'blue': flowcoord['TRACK_BLUE']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:56.657773Z",
     "iopub.status.busy": "2025-03-10T16:07:56.657412Z",
     "iopub.status.idle": "2025-03-10T16:07:56.668973Z",
     "shell.execute_reply": "2025-03-10T16:07:56.667960Z",
     "shell.execute_reply.started": "2025-03-10T16:07:56.657736Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def update_nearest_halte(train_df, test_df):\n",
    "\n",
    "    # Add a column for halte_distance only\n",
    "    train_df['halte_distance'] = np.nan     # jarak ke halte terdekat (dalam meter)\n",
    "    test_df['halte_distance'] = np.nan\n",
    "\n",
    "    # For each color, calculate halte distance for train_df\n",
    "    for color_val in ['red', 'blue']:\n",
    "        route_key = color_to_route[color_val]             # e.g. 'red' -> 'RUTE_MERAH'\n",
    "        stop_coords = stops_data[route_key]['coords']       # array koordinat halte\n",
    "        # Subset rows for the given color\n",
    "        mask = train_df['color'] == color_val\n",
    "        lat_points = train_df.loc[mask, 'lat'].to_numpy()\n",
    "        lon_points = train_df.loc[mask, 'lon'].to_numpy()\n",
    "        if lat_points.size == 0:\n",
    "            continue\n",
    "\n",
    "        lat_diff = lat_points[:, None] - stop_coords[:, 0][None, :]\n",
    "        lon_diff = lon_points[:, None] - stop_coords[:, 1][None, :]\n",
    "        cos_lat = np.cos(np.deg2rad(lat_points))\n",
    "        lat_diff_m = lat_diff * 111320.0\n",
    "        lon_diff_m = lon_diff * (111320.0 * cos_lat[:, None])\n",
    "        dist_sq = lat_diff_m**2 + lon_diff_m**2\n",
    "        min_dist = np.sqrt(np.min(dist_sq, axis=1))\n",
    "        train_df.loc[mask, 'halte_distance'] = min_dist\n",
    "\n",
    "    # For each color, calculate halte distance for test_df\n",
    "    for color_val in ['red', 'blue']:\n",
    "        route_key = color_to_route[color_val]             # e.g., 'red' -> 'RUTE_MERAH'\n",
    "        stop_coords = stops_data[route_key]['coords']\n",
    "        mask = test_df['color'] == color_val\n",
    "        lat_points = test_df.loc[mask, 'lat'].to_numpy()\n",
    "        lon_points = test_df.loc[mask, 'lon'].to_numpy()\n",
    "        if lat_points.size == 0:\n",
    "            continue\n",
    "\n",
    "        lat_diff = lat_points[:, None] - stop_coords[:, 0][None, :]\n",
    "        lon_diff = lon_points[:, None] - stop_coords[:, 1][None, :]\n",
    "        cos_lat = np.cos(np.deg2rad(lat_points))\n",
    "        lat_diff_m = lat_diff * 111320.0\n",
    "        lon_diff_m = lon_diff * (111320.0 * cos_lat[:, None])\n",
    "        dist_sq = lat_diff_m**2 + lon_diff_m**2\n",
    "        min_dist = np.sqrt(np.min(dist_sq, axis=1))\n",
    "        test_df.loc[mask, 'halte_distance'] = min_dist\n",
    "\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:56.670381Z",
     "iopub.status.busy": "2025-03-10T16:07:56.669957Z",
     "iopub.status.idle": "2025-03-10T16:07:56.692245Z",
     "shell.execute_reply": "2025-03-10T16:07:56.691254Z",
     "shell.execute_reply.started": "2025-03-10T16:07:56.670346Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def update_route_distance(train_df, test_df, track_data):\n",
    "    import numpy as np\n",
    "\n",
    "    train_df['route_distance'] = np.nan\n",
    "    test_df['route_distance'] = np.nan\n",
    "\n",
    "    for color_val in ['red', 'blue']:\n",
    "        track_key = 'TRACK_' + color_val.upper()          # e.g. 'red' -> 'TRACK_RED'\n",
    "        track_coords = track_data[track_key]              # array titik-titik jalur rute\n",
    "        mask = train_df['color'] == color_val\n",
    "        lat_points = train_df.loc[mask, 'lat'].to_numpy()\n",
    "        lon_points = train_df.loc[mask, 'lon'].to_numpy()\n",
    "        if lat_points.size == 0:\n",
    "            continue\n",
    "\n",
    "        # Hitung jarak terdekat ke jalur (gunakan tiap titik jalur sebagai referensi)\n",
    "        lat_diff = lat_points[:, None] - track_coords[:, 0][None, :]\n",
    "        lon_diff = lon_points[:, None] - track_coords[:, 1][None, :]\n",
    "        cos_lat = np.cos(np.deg2rad(lat_points))\n",
    "        lat_diff_m = lat_diff * 111320.0\n",
    "        lon_diff_m = lon_diff * (111320.0 * cos_lat[:, None])\n",
    "        dist_sq = lat_diff_m**2 + lon_diff_m**2\n",
    "        min_dist = np.sqrt(np.min(dist_sq, axis=1))  # jarak ke titik jalur terdekat\n",
    "        train_df.loc[mask, 'route_distance'] = min_dist\n",
    "\n",
    "    for color_val in ['red', 'blue']:\n",
    "        track_key = 'TRACK_' + color_val.upper()          # e.g. 'red' -> 'TRACK_RED'\n",
    "        track_coords = track_data[track_key]              # array titik-titik jalur rute\n",
    "        mask = test_df['color'] == color_val\n",
    "        lat_points = test_df.loc[mask, 'lat'].to_numpy()\n",
    "        lon_points = test_df.loc[mask, 'lon'].to_numpy()\n",
    "        if lat_points.size == 0:\n",
    "            continue\n",
    "\n",
    "        # Hitung jarak terdekat ke jalur (gunakan tiap titik jalur sebagai referensi)\n",
    "        lat_diff = lat_points[:, None] - track_coords[:, 0][None, :]\n",
    "        lon_diff = lon_points[:, None] - track_coords[:, 1][None, :]\n",
    "        cos_lat = np.cos(np.deg2rad(lat_points))\n",
    "        lat_diff_m = lat_diff * 111320.0\n",
    "        lon_diff_m = lon_diff * (111320.0 * cos_lat[:, None])\n",
    "        dist_sq = lat_diff_m**2 + lon_diff_m**2\n",
    "        min_dist = np.sqrt(np.min(dist_sq, axis=1))  # jarak ke titik jalur terdekat\n",
    "        test_df.loc[mask, 'route_distance'] = min_dist\n",
    "\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:56.696038Z",
     "iopub.status.busy": "2025-03-10T16:07:56.695752Z",
     "iopub.status.idle": "2025-03-10T16:07:56.716185Z",
     "shell.execute_reply": "2025-03-10T16:07:56.714960Z",
     "shell.execute_reply.started": "2025-03-10T16:07:56.696014Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000  # radius bumi dalam meter\n",
    "    phi1, phi2 = math.radians(lat1), math.radians(lat2)\n",
    "    d_phi = math.radians(lat2 - lat1)\n",
    "    d_lambda = math.radians(lon2 - lon1)\n",
    "    a = math.sin(d_phi / 2) ** 2 + math.cos(phi1) * math.cos(phi2) * math.sin(d_lambda / 2) ** 2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "# Fungsi mendapatkan titik terdekat pada jalur (flowcoord)\n",
    "def get_closest_point_on_route(lat, lon, flowcoord):\n",
    "    line = LineString([(pt[\"longitude\"], pt[\"latitude\"]) for pt in flowcoord])\n",
    "    point = Point(lon, lat)\n",
    "    proj_point = line.interpolate(line.project(point))\n",
    "    return proj_point.y, proj_point.x\n",
    "\n",
    "# Fungsi mendapatkan halte terdekat berdasarkan koordinat di flowcoord\n",
    "def get_nearest_stop_from_flowcoord(lat, lon, flowcoord):\n",
    "    min_distance = float('inf')\n",
    "    nearest_stop = None\n",
    "    for pt in flowcoord:\n",
    "        if pt[\"name\"]:  # hanya pertimbangkan titik dengan nama (halte)\n",
    "            stop_lat, stop_lon = pt[\"latitude\"], pt[\"longitude\"]\n",
    "            dist = haversine(lat, lon, stop_lat, stop_lon)\n",
    "            if dist < min_distance:\n",
    "                min_distance = dist\n",
    "                nearest_stop = pt[\"name\"]\n",
    "    return nearest_stop, min_distance\n",
    "\n",
    "# Fungsi utama menghitung halte dan jarak terdekat berbasis flowcoord\n",
    "def assign_nearest_stop_from_flowcoord(df, flowcoord_dict):\n",
    "    df = df.copy()\n",
    "    df['nearest_stop'] = None\n",
    "    df['distance_to_stop'] = np.nan\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        color = row['color'].lower()\n",
    "        flowcoord = flowcoord_dict[color]\n",
    "\n",
    "        # Dapatkan koordinat bus yang terproyeksi di rute flowcoord\n",
    "        proj_lat, proj_lon = get_closest_point_on_route(row['lat'], row['lon'], flowcoord)\n",
    "\n",
    "        # Dapatkan halte terdekat dari koordinat terproyeksi\n",
    "        nearest_stop, distance_to_stop = get_nearest_stop_from_flowcoord(proj_lat, proj_lon, flowcoord)\n",
    "\n",
    "        # Assign ke dataframe\n",
    "        df.at[idx, 'nearest_stop'] = nearest_stop\n",
    "        df.at[idx, 'distance_to_stop'] = distance_to_stop\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:56.718463Z",
     "iopub.status.busy": "2025-03-10T16:07:56.718154Z",
     "iopub.status.idle": "2025-03-10T16:07:56.739850Z",
     "shell.execute_reply": "2025-03-10T16:07:56.738664Z",
     "shell.execute_reply.started": "2025-03-10T16:07:56.718437Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def initialize_stop_columns(train_df, test_df):\n",
    "    import numpy as np\n",
    "    train_df['nearest_stop'] = None\n",
    "    train_df['distance_to_stop'] = np.nan\n",
    "    test_df['nearest_stop'] = None\n",
    "    test_df['distance_to_stop'] = np.nan\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:56.741693Z",
     "iopub.status.busy": "2025-03-10T16:07:56.741321Z",
     "iopub.status.idle": "2025-03-10T16:07:56.759771Z",
     "shell.execute_reply": "2025-03-10T16:07:56.758539Z",
     "shell.execute_reply.started": "2025-03-10T16:07:56.741653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def convert_timestamps(train_df, test_df):\n",
    "    import pandas as pd\n",
    "    train_df['ts'] = pd.to_datetime(train_df['ts'])\n",
    "    test_df['ts'] = pd.to_datetime(test_df['ts'])\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:56.762836Z",
     "iopub.status.busy": "2025-03-10T16:07:56.762333Z",
     "iopub.status.idle": "2025-03-10T16:07:56.776059Z",
     "shell.execute_reply": "2025-03-10T16:07:56.774851Z",
     "shell.execute_reply.started": "2025-03-10T16:07:56.762794Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def add_prev_next_stop_features(df, red_stops, blue_stops):\n",
    "\n",
    "    df = df.copy()\n",
    "    df['distance_to_prev_stop'] = np.nan\n",
    "    df['distance_to_next_stop'] = np.nan\n",
    "\n",
    "    def get_stop_index(nearest_stop, stops_list):\n",
    "        for idx, (stop_name, coords) in enumerate(stops_list):\n",
    "            if stop_name == nearest_stop:\n",
    "                return idx\n",
    "        return None\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        # Pilih list halte berdasarkan warna rute\n",
    "        stops_list = red_stops if row['color'] == 'red' else blue_stops\n",
    "        nearest_stop = row.get('nearest_stop')\n",
    "        if pd.isnull(nearest_stop) or nearest_stop is None:\n",
    "            continue\n",
    "        \n",
    "        idx_stop = get_stop_index(nearest_stop, stops_list)\n",
    "        if idx_stop is None:\n",
    "            continue\n",
    "\n",
    "        lat, lon = row['lat'], row['lon']\n",
    "        # Calculate distance to previous stop:\n",
    "        if idx_stop > 0:\n",
    "            prev_coords = stops_list[idx_stop - 1][1]\n",
    "        else:\n",
    "            # Wrap-around: if at the first stop, use the last stop as previous\n",
    "            prev_coords = stops_list[-1][1]\n",
    "        dist_prev = haversine(lat, lon, prev_coords[0], prev_coords[1])\n",
    "        df.at[idx, 'distance_to_prev_stop'] = dist_prev\n",
    "\n",
    "        # Calculate distance to next stop:\n",
    "        if idx_stop < len(stops_list) - 1:\n",
    "            next_coords = stops_list[idx_stop + 1][1]\n",
    "        else:\n",
    "            # Wrap-around: if at the last stop, use the first stop as next\n",
    "            next_coords = stops_list[0][1]\n",
    "        dist_next = haversine(lat, lon, next_coords[0], next_coords[1])\n",
    "        df.at[idx, 'distance_to_next_stop'] = dist_next\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:56.777615Z",
     "iopub.status.busy": "2025-03-10T16:07:56.777221Z",
     "iopub.status.idle": "2025-03-10T16:07:56.799246Z",
     "shell.execute_reply": "2025-03-10T16:07:56.798201Z",
     "shell.execute_reply.started": "2025-03-10T16:07:56.777579Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_time_diff(df, boole = False):\n",
    "    \n",
    "    df = df.copy()\n",
    "    df['ts'] = pd.to_datetime(df['ts'])\n",
    "    df['time_diff'] = df['ts'].diff().dt.total_seconds()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:56.800756Z",
     "iopub.status.busy": "2025-03-10T16:07:56.800371Z",
     "iopub.status.idle": "2025-03-10T16:07:56.815705Z",
     "shell.execute_reply": "2025-03-10T16:07:56.814505Z",
     "shell.execute_reply.started": "2025-03-10T16:07:56.800717Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_rta(df):\n",
    "    \n",
    "\n",
    "    # Tambah kolom tanggal untuk memisahkan per hari\n",
    "    df['tanggal'] = df['ts'].dt.date\n",
    "\n",
    "    # Fungsi utama\n",
    "    def process_daily_group(daily_df):\n",
    "        marker_indices = []\n",
    "        current_halte = None\n",
    "        current_min_dist = None\n",
    "        current_min_idx = None\n",
    "\n",
    "        for i, row in daily_df.iterrows():\n",
    "            halte = row['nearest_stop']\n",
    "            dist = row['halte_distance']\n",
    "\n",
    "            if halte != current_halte:\n",
    "                if current_min_idx is not None:\n",
    "                    marker_indices.append(current_min_idx)\n",
    "\n",
    "                current_halte = halte\n",
    "                current_min_dist = dist\n",
    "                current_min_idx = i\n",
    "            else:\n",
    "                if dist < current_min_dist:\n",
    "                    current_min_dist = dist\n",
    "                    current_min_idx = i\n",
    "\n",
    "        if current_min_idx is not None:\n",
    "            marker_indices.append(current_min_idx)\n",
    "\n",
    "        def get_next_marker(idx):\n",
    "            for marker in marker_indices:\n",
    "                if marker > idx:\n",
    "                    return marker\n",
    "            return None\n",
    "\n",
    "        def compute_rta_row(row):\n",
    "            next_marker = get_next_marker(row.name)\n",
    "            if next_marker is not None:\n",
    "                return (daily_df.loc[next_marker, 'ts'] - row['ts']).total_seconds()\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        daily_df['rta'] = daily_df.apply(compute_rta_row, axis=1)\n",
    "\n",
    "        return daily_df\n",
    "\n",
    "    # Proses tiap hari secara terpisah\n",
    "    df = df.groupby('tanggal', group_keys=False).apply(process_daily_group).reset_index(drop=True)\n",
    "\n",
    "    df.drop(columns=['tanggal'], inplace=True)\n",
    "    df.drop(columns = [\"time_diff\"], inplace = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:56.817217Z",
     "iopub.status.busy": "2025-03-10T16:07:56.816804Z",
     "iopub.status.idle": "2025-03-10T16:07:56.839586Z",
     "shell.execute_reply": "2025-03-10T16:07:56.838346Z",
     "shell.execute_reply.started": "2025-03-10T16:07:56.817180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def add_time_series_features(df, ts_column='ts'):\n",
    "\n",
    "    df[ts_column] = pd.to_datetime(df[ts_column])\n",
    "    \n",
    "    # Basic features (to be dropped later)\n",
    "    df['year'] = df[ts_column].dt.year\n",
    "    df['month'] = df[ts_column].dt.month\n",
    "    df['day'] = df[ts_column].dt.day\n",
    "    df['weekday'] = df[ts_column].dt.weekday\n",
    "    df['weekofyear'] = df[ts_column].dt.isocalendar().week.astype(int)\n",
    "    df['hour'] = df[ts_column].dt.hour\n",
    "    df['minute'] = df[ts_column].dt.minute\n",
    "    df['second'] = df[ts_column].dt.second\n",
    "    df['quarter'] = df[ts_column].dt.quarter\n",
    "\n",
    "    # Cyclical features\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "\n",
    "    df['minute_sin'] = np.sin(2 * np.pi * df['minute'] / 60)\n",
    "    df['minute_cos'] = np.cos(2 * np.pi * df['minute'] / 60)\n",
    "\n",
    "    df['second_sin'] = np.sin(2 * np.pi * df['second'] / 60)\n",
    "    df['second_cos'] = np.cos(2 * np.pi * df['second'] / 60)\n",
    "\n",
    "    df['weekday_sin'] = np.sin(2 * np.pi * df['weekday'] / 7)\n",
    "    df['weekday_cos'] = np.cos(2 * np.pi * df['weekday'] / 7)\n",
    "\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "\n",
    "    df['weekofyear_sin'] = np.sin(2 * np.pi * df['weekofyear'] / 52)\n",
    "    df['weekofyear_cos'] = np.cos(2 * np.pi * df['weekofyear'] / 52)\n",
    "    \n",
    "    # Now drop the non-cyclical (basic) time features:\n",
    "    basic_features = ['year', 'month', 'day', 'weekday', 'weekofyear', 'hour', 'minute', 'second', 'quarter']\n",
    "    df = df.drop(columns=basic_features)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:56.841592Z",
     "iopub.status.busy": "2025-03-10T16:07:56.841100Z",
     "iopub.status.idle": "2025-03-10T16:07:56.862460Z",
     "shell.execute_reply": "2025-03-10T16:07:56.861229Z",
     "shell.execute_reply.started": "2025-03-10T16:07:56.841547Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def has_passed_nearest_stop(row, flowcoord_dict):\n",
    "\n",
    "    # Tentukan rute berdasarkan kolom 'color' (misalnya 'red' atau 'blue')\n",
    "    route = row['color'].lower()\n",
    "    flowcoord_list = flowcoord_dict.get(route)\n",
    "    if flowcoord_list is None:\n",
    "        return np.nan  # Jika tidak ada data flowcoord, tidak bisa dihitung\n",
    "    \n",
    "    # Buat LineString dari flowcoord (ingat urutan (longitude, latitude))\n",
    "    line = LineString([(pt[\"longitude\"], pt[\"latitude\"]) for pt in flowcoord_list])\n",
    "    \n",
    "    # Cari titik marker halte sesuai 'nearest_stop'\n",
    "    marker = None\n",
    "    for pt in flowcoord_list:\n",
    "        if pt.get(\"name\") == row['nearest_stop']:\n",
    "            marker = pt\n",
    "            break\n",
    "    if marker is None:\n",
    "        # Jika marker tidak ditemukan, kembalikan np.nan atau False sesuai kebijakan\n",
    "        return np.nan\n",
    "    \n",
    "    # Buat titik untuk marker halte dan posisi bus\n",
    "    stop_point = Point(marker[\"longitude\"], marker[\"latitude\"])\n",
    "    bus_point = Point(row['lon'], row['lat'])\n",
    "    \n",
    "    # Dapatkan jarak kumulatif (proyeksi) pada LineString untuk marker dan bus\n",
    "    stop_proj = line.project(stop_point)\n",
    "    bus_proj = line.project(bus_point)\n",
    "    \n",
    "    # Jika bus_proj >= stop_proj, artinya bus sudah melewati (atau tepat di titik) marker halte\n",
    "    return bus_proj >= stop_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:56.863981Z",
     "iopub.status.busy": "2025-03-10T16:07:56.863665Z",
     "iopub.status.idle": "2025-03-10T16:07:56.889298Z",
     "shell.execute_reply": "2025-03-10T16:07:56.887999Z",
     "shell.execute_reply.started": "2025-03-10T16:07:56.863943Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def adjust_local_min_rta_improved(df, dwell_time=15, tolerance_distance=10):\n",
    "    \n",
    "    n = len(df)\n",
    "    start = 0\n",
    "    while start < n:\n",
    "        current_halte = df.loc[start, 'nearest_stop']\n",
    "        end = start\n",
    "        # Bentuk blok: baris-baris dengan 'nearest_halte' yang sama\n",
    "        while end < n and df.loc[end, 'nearest_stop'] == current_halte:\n",
    "            end += 1\n",
    "        \n",
    "        block = df.iloc[start:end]\n",
    "        if not block.empty:\n",
    "            # Cari baris dengan 'halte_distance' terkecil dalam blok tersebut\n",
    "            idx_min = block['halte_distance'].idxmin()\n",
    "            # Jika baris tersebut belum passed atau (sudah passed tetapi jaraknya < tolerance_distance)\n",
    "            if (not df.loc[idx_min, 'passed_stop']) or (df.loc[idx_min, 'passed_stop'] and df.loc[idx_min, 'halte_distance'] < tolerance_distance):\n",
    "                new_rta = (df.loc[idx_min, 'halte_distance'] * 3.6 / 8)\n",
    "                df.loc[idx_min, 'rta'] = new_rta\n",
    "        start = end\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:56.890900Z",
     "iopub.status.busy": "2025-03-10T16:07:56.890519Z",
     "iopub.status.idle": "2025-03-10T16:07:56.918192Z",
     "shell.execute_reply": "2025-03-10T16:07:56.916976Z",
     "shell.execute_reply.started": "2025-03-10T16:07:56.890860Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def separate_outside_and_short_route(df, flowcoord_dict, start_stop='tempat_turun_asrama', end_stop='asrama_ui_01_end'):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Buat LineString jalur penuh\n",
    "    full_routes = {}\n",
    "    short_routes = {}\n",
    "\n",
    "    for color, coords in flowcoord_dict.items():\n",
    "        line_full = LineString([(pt['longitude'], pt['latitude']) for pt in coords])\n",
    "        full_routes[color] = line_full\n",
    "\n",
    "        # Potong jalur pendek (dari start_stop ke end_stop)\n",
    "        start_idx, end_idx = None, None\n",
    "        for i, pt in enumerate(coords):\n",
    "            if pt['name'] == start_stop:\n",
    "                start_idx = i\n",
    "            elif pt['name'] == end_stop:\n",
    "                end_idx = i\n",
    "                break\n",
    "\n",
    "        if start_idx is not None and end_idx is not None and start_idx < end_idx:\n",
    "            short_route_coords = coords[start_idx:end_idx + 1]\n",
    "        else:\n",
    "            short_route_coords = coords[end_idx:start_idx + 1]\n",
    "\n",
    "        line_short = LineString([(pt['longitude'], pt['latitude']) for pt in short_route_coords])\n",
    "        short_routes[color] = line_short\n",
    "\n",
    "    # Pisahkan data\n",
    "    outside_flowcoord = []\n",
    "    short_route_data = []\n",
    "    normal_route_data = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        bus_point = Point(row['lon'], row['lat'])\n",
    "        color = row['color'].lower()\n",
    "\n",
    "        # Jarak terdekat ke jalur utama\n",
    "        dist_to_full_route = bus_point.distance(full_routes[color])\n",
    "\n",
    "        # Threshold (misalnya, 50 meter dari jalur utama dianggap di luar jalur)\n",
    "        if dist_to_full_route > 0.0005:  # ~50m dalam derajat\n",
    "            outside_flowcoord.append(idx)\n",
    "            continue\n",
    "\n",
    "        # Cek apakah di jalur pendek khusus\n",
    "        dist_to_short_route = bus_point.distance(short_routes[color])\n",
    "\n",
    "        if dist_to_short_route <= 0.0005:\n",
    "            short_route_data.append(idx)\n",
    "        else:\n",
    "            normal_route_data.append(idx)\n",
    "\n",
    "    df_outside_flowcoord = df.loc[outside_flowcoord]\n",
    "    df_short_route = df.loc[short_route_data]\n",
    "    df_normal_route = df.loc[normal_route_data]\n",
    "\n",
    "    return df_outside_flowcoord, df_short_route, df_normal_route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:56.919739Z",
     "iopub.status.busy": "2025-03-10T16:07:56.919359Z",
     "iopub.status.idle": "2025-03-10T16:07:56.941542Z",
     "shell.execute_reply": "2025-03-10T16:07:56.940402Z",
     "shell.execute_reply.started": "2025-03-10T16:07:56.919702Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def filter_train_data(df_normal, df_short_route, df_outside):\n",
    "    train_df_normal = df_normal[\n",
    "        (df_normal['rta'] >= 0) & (df_normal['rta'] <= 500) &\n",
    "        (df_normal['speed'] >= 0) & (df_normal['speed'] <= 100)\n",
    "    ].copy()\n",
    "\n",
    "    # For df_short_route, also keep rows where rta is between 0 and 500 and speed is between 0 and 100.\n",
    "    train_df_short_route = df_short_route[\n",
    "        (df_short_route['rta'] >= 0) &\n",
    "        (df_short_route['speed'] >= 0) & (df_short_route['speed'] <= 100)\n",
    "    ].copy()\n",
    "\n",
    "    # For df_outside, likewise keep rows where rta is between 0 and 500 and speed is between 0 and 100.\n",
    "    train_df_outside = df_outside[\n",
    "        (df_outside['rta'] >= 0) &\n",
    "        (df_outside['speed'] >= 0) & (df_outside['speed'] <= 100)\n",
    "    ].copy()\n",
    "\n",
    "    return train_df_normal, train_df_short_route, train_df_outside\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:56.943280Z",
     "iopub.status.busy": "2025-03-10T16:07:56.942826Z",
     "iopub.status.idle": "2025-03-10T16:07:56.961188Z",
     "shell.execute_reply": "2025-03-10T16:07:56.959910Z",
     "shell.execute_reply.started": "2025-03-10T16:07:56.943234Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def cut_excess_same_group_speed_zero(\n",
    "    df,\n",
    "    group_cols = [\n",
    "        'speed',\n",
    "        'halte_distance',\n",
    "        'route_distance',\n",
    "        'nearest_stop',\n",
    "        'distance_to_stop',\n",
    "        'distance_to_prev_stop',\n",
    "        'distance_to_next_stop'\n",
    "    ],\n",
    "    max_rows=2\n",
    "):\n",
    "    \n",
    "    # Separate the subset where speed=0\n",
    "    df_speed_zero = df[df['speed'] == 0].copy()\n",
    "    # Subset where speed != 0 remains untouched\n",
    "    df_not_zero = df[df['speed'] != 0]\n",
    "\n",
    "    # We'll store filtered groups here\n",
    "    filtered_groups = []\n",
    "\n",
    "    # Group the speed=0 subset by the chosen columns\n",
    "    grouped = df_speed_zero.groupby(group_cols, dropna=False)  # dropna=False to include NaN in grouping if present\n",
    "\n",
    "    for group_key, group_df in grouped:\n",
    "        if len(group_df) > max_rows:\n",
    "            # Sort by rta ascending, keep only top `max_rows`\n",
    "            group_df = group_df.sort_values('rta', ascending=True).head(max_rows)\n",
    "        filtered_groups.append(group_df)\n",
    "\n",
    "    # Combine the filtered speed=0 groups\n",
    "    df_speed_zero_filtered = pd.concat(filtered_groups, ignore_index=True)\n",
    "\n",
    "    # Combine with the rest of the DataFrame (where speed != 0)\n",
    "    df_filtered = pd.concat([df_not_zero, df_speed_zero_filtered], ignore_index=True)\n",
    "\n",
    "    # Calculate how many rows were dropped\n",
    "    dropped_count = len(df) - len(df_filtered)\n",
    "\n",
    "    return df_filtered, dropped_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:56.962704Z",
     "iopub.status.busy": "2025-03-10T16:07:56.962386Z",
     "iopub.status.idle": "2025-03-10T16:07:56.987020Z",
     "shell.execute_reply": "2025-03-10T16:07:56.985593Z",
     "shell.execute_reply.started": "2025-03-10T16:07:56.962677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(df, column, factor=1.5):\n",
    "\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - factor * IQR\n",
    "    upper_bound = Q3 + factor * IQR\n",
    "    filtered_df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)].copy()\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:56.988717Z",
     "iopub.status.busy": "2025-03-10T16:07:56.988325Z",
     "iopub.status.idle": "2025-03-10T16:07:57.011495Z",
     "shell.execute_reply": "2025-03-10T16:07:57.009700Z",
     "shell.execute_reply.started": "2025-03-10T16:07:56.988678Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load and define stops and flowcoord dictionary\n",
    "\n",
    "\n",
    "def process(train_df, test_df):\n",
    "    \n",
    "    preprocess_json()\n",
    "    update_flowcoord_tracks()\n",
    "    red_stops = list(routes[\"RUTE_MERAH\"].items())\n",
    "    blue_stops = list(routes[\"RUTE_BIRU\"].items())\n",
    "    train_df, test_df = convert_timestamps(train_df, test_df)\n",
    "    train_df, test_df = update_nearest_halte(train_df, test_df)\n",
    "    train_df, test_df = update_route_distance(train_df, test_df, track_data)\n",
    "    train_df, test_df = initialize_stop_columns(train_df, test_df)\n",
    "    train_df = assign_nearest_stop_from_flowcoord(train_df, flowcoord_dict)\n",
    "    test_df = assign_nearest_stop_from_flowcoord(test_df, flowcoord_dict)\n",
    "    test_df = add_prev_next_stop_features(test_df, red_stops, blue_stops)\n",
    "    train_df = add_prev_next_stop_features(train_df, red_stops, blue_stops)\n",
    "    train_df = compute_time_diff(train_df)\n",
    "    train_df = compute_rta(train_df)\n",
    "    \n",
    "    test_df = compute_time_diff(test_df)\n",
    "    test_df = compute_rta(test_df)\n",
    "    \n",
    "    train_df = add_time_series_features(train_df)\n",
    "    test_df = add_time_series_features(test_df)\n",
    "    train_df['passed_stop'] = train_df.apply(lambda row: has_passed_nearest_stop(row, flowcoord_dict), axis=1)\n",
    "    test_df['passed_stop'] = test_df.apply(lambda row: has_passed_nearest_stop(row, flowcoord_dict), axis=1)\n",
    "    \n",
    "    # Separate training data into groups\n",
    "    df_outside, df_short_route, df_normal = separate_outside_and_short_route(train_df, flowcoord_dict)\n",
    "    \n",
    "    # Filter train data (e.g., clip rta values, speed, etc.)\n",
    "    train_df_normal, train_df_short_route, train_df_outside = filter_train_data(df_normal, df_short_route, df_outside)\n",
    "    \n",
    "    # Remove excessive rows (based on speed==0 block logic)\n",
    "    train_df_normal, dropped_count = cut_excess_same_group_speed_zero(train_df_normal)\n",
    "    train_df_short_route, dropped_count2 = cut_excess_same_group_speed_zero(train_df_short_route)\n",
    "    train_df_outside, dropped_count3 = cut_excess_same_group_speed_zero(train_df_outside)\n",
    "    \n",
    "    # Remove outliers on 'rta'\n",
    "    train_df_normal_clean = remove_outliers_iqr(train_df_normal, 'rta', factor=1.5)\n",
    "    train_df_short_route_clean = remove_outliers_iqr(train_df_short_route, 'rta', factor=1.5)\n",
    "    train_df_outside_clean = remove_outliers_iqr(train_df_outside, 'rta', factor=1.5)\n",
    "    \n",
    "    # Separate test data into groups using flowcoord\n",
    "    test_outside, test_short_route, test_normal = separate_outside_and_short_route(test_df, flowcoord_dict)\n",
    "    \n",
    "    print(f\"Number of rows dropped: {dropped_count} {dropped_count2} {dropped_count3}\")\n",
    "    print(\"Normal group shape before:\", df_normal.shape, \"after:\", train_df_normal_clean.shape)\n",
    "    print(\"Short route group shape before:\", df_short_route.shape, \"after:\", train_df_short_route_clean.shape)\n",
    "    print(\"Outside group shape before:\", df_outside.shape, \"after:\", train_df_outside_clean.shape)\n",
    "    \n",
    "    return {\n",
    "        'train_df_normal_clean': train_df_normal_clean,\n",
    "        'train_df_short_route_clean': train_df_short_route_clean,\n",
    "        'train_df_outside_clean': train_df_outside_clean,\n",
    "        'test_normal': test_normal,\n",
    "        'test_short_route': test_short_route,\n",
    "        'test_outside': test_outside,\n",
    "        'train_df': train_df,  # full processed train_df if needed\n",
    "        'test_df': test_df     # full processed test_df if needed\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:57.012951Z",
     "iopub.status.busy": "2025-03-10T16:07:57.012592Z",
     "iopub.status.idle": "2025-03-10T16:07:57.034047Z",
     "shell.execute_reply": "2025-03-10T16:07:57.032353Z",
     "shell.execute_reply.started": "2025-03-10T16:07:57.012920Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "def build_models_with_best_params(train_processed, best_params, \n",
    "                                  cat_features=['color', 'nearest_stop', 'passed_stop'], \n",
    "                                  exclude_cols=['rta', 'imei', 'ts']):\n",
    "\n",
    "    # Build feature lists by dropping the excluded columns.\n",
    "    features_normal = [col for col in train_processed['df_normal'].columns if col not in exclude_cols]\n",
    "    features_short  = [col for col in train_processed['df_short_route'].columns if col not in exclude_cols]\n",
    "    features_outside = [col for col in train_processed['df_outside'].columns if col not in exclude_cols]\n",
    "    \n",
    "    # Extract training features and target for each group.\n",
    "    X_normal = train_processed['df_normal'][features_normal]\n",
    "    y_normal = train_processed['df_normal']['rta']\n",
    "    \n",
    "    X_short = train_processed['df_short_route'][features_short]\n",
    "    y_short = train_processed['df_short_route']['rta']\n",
    "    \n",
    "    X_outside = train_processed['df_outside'][features_outside]\n",
    "    y_outside = train_processed['df_outside']['rta']\n",
    "    \n",
    "    # Instantiate models using the best parameters.\n",
    "    model_normal = CatBoostRegressor(**best_params['normal'], random_seed=42, verbose=100, cat_features=cat_features)\n",
    "    model_short  = CatBoostRegressor(**best_params['short'], random_seed=42, verbose=100, cat_features=cat_features)\n",
    "    model_outside = CatBoostRegressor(**best_params['outside'], random_seed=42, verbose=100, cat_features=cat_features)\n",
    "    \n",
    "    # Train the models.\n",
    "    model_normal.fit(X_normal, y_normal)\n",
    "    model_short.fit(X_short, y_short)\n",
    "    model_outside.fit(X_outside, y_outside)\n",
    "    \n",
    "    models = {\n",
    "        'normal': model_normal,\n",
    "        'short': model_short,\n",
    "        'outside': model_outside\n",
    "    }\n",
    "    \n",
    "    feature_lists = {\n",
    "        'features_normal': features_normal,\n",
    "        'features_short': features_short,\n",
    "        'features_outside': features_outside\n",
    "    }\n",
    "    \n",
    "    return models, feature_lists\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:57.035988Z",
     "iopub.status.busy": "2025-03-10T16:07:57.035664Z",
     "iopub.status.idle": "2025-03-10T16:07:57.063742Z",
     "shell.execute_reply": "2025-03-10T16:07:57.061230Z",
     "shell.execute_reply.started": "2025-03-10T16:07:57.035961Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def infer(models, train_processed, test_processed):\n",
    "    \n",
    "\n",
    "    exclude_cols = ['rta', 'imei', 'ts']\n",
    "    \n",
    "\n",
    "    features_normal = [col for col in train_processed['df_normal'].columns if col not in exclude_cols]\n",
    "    features_short  = [col for col in train_processed['df_short_route'].columns if col not in exclude_cols]\n",
    "    features_outside = [col for col in train_processed['df_outside'].columns if col not in exclude_cols]\n",
    "    \n",
    "\n",
    "    test_normal = test_processed['test_normal'].copy()\n",
    "    test_short  = test_processed['test_short_route'].copy()\n",
    "    test_outside = test_processed['test_outside'].copy()\n",
    "    \n",
    "\n",
    "    test_normal['predicted_rta'] = models['normal'].predict(test_normal[features_normal])\n",
    "    test_short['predicted_rta']  = models['short'].predict(test_short[features_short])\n",
    "    test_outside['predicted_rta'] = models['outside'].predict(test_outside[features_outside])\n",
    "    \n",
    "\n",
    "    final_predictions = pd.concat([test_normal, test_short, test_outside])\n",
    "    \n",
    "\n",
    "    if 'Id' in final_predictions.columns:\n",
    "        final_predictions = final_predictions.sort_values(by='Id').reset_index(drop=True)\n",
    "    else:\n",
    "        final_predictions = final_predictions.sort_values(by='ts').reset_index(drop=True)\n",
    "    \n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:07:57.065831Z",
     "iopub.status.busy": "2025-03-10T16:07:57.065324Z",
     "iopub.status.idle": "2025-03-10T16:10:07.760959Z",
     "shell.execute_reply": "2025-03-10T16:10:07.759998Z",
     "shell.execute_reply.started": "2025-03-10T16:07:57.065787Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/shapely/linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "/usr/local/lib/python3.10/dist-packages/shapely/linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "<ipython-input-14-54f7dbfc9e56>:51: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('tanggal', group_keys=False).apply(process_daily_group).reset_index(drop=True)\n",
      "<ipython-input-14-54f7dbfc9e56>:51: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('tanggal', group_keys=False).apply(process_daily_group).reset_index(drop=True)\n",
      "/usr/local/lib/python3.10/dist-packages/shapely/linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "/usr/local/lib/python3.10/dist-packages/shapely/linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows dropped: 3033 1619 64\n",
      "Normal group shape before: (31546, 26) after: (26481, 26)\n",
      "Short route group shape before: (3913, 26) after: (1964, 26)\n",
      "Outside group shape before: (1932, 26) after: (1740, 26)\n",
      "0:\tlearn: 40.9272727\ttotal: 82ms\tremaining: 1m 16s\n",
      "100:\tlearn: 30.4854836\ttotal: 2.07s\tremaining: 17.1s\n",
      "200:\tlearn: 28.5723483\ttotal: 4.1s\tremaining: 15s\n",
      "300:\tlearn: 27.2124939\ttotal: 6.13s\tremaining: 12.9s\n",
      "400:\tlearn: 26.1121624\ttotal: 8.22s\tremaining: 10.9s\n",
      "500:\tlearn: 25.1301165\ttotal: 10.3s\tremaining: 8.88s\n",
      "600:\tlearn: 24.1734010\ttotal: 12.3s\tremaining: 6.83s\n",
      "700:\tlearn: 23.3346100\ttotal: 14.3s\tremaining: 4.77s\n",
      "800:\tlearn: 22.5462028\ttotal: 16.4s\tremaining: 2.74s\n",
      "900:\tlearn: 21.8412845\ttotal: 18.4s\tremaining: 695ms\n",
      "934:\tlearn: 21.6200958\ttotal: 19.1s\tremaining: 0us\n",
      "0:\tlearn: 206.0527040\ttotal: 18ms\tremaining: 12.7s\n",
      "100:\tlearn: 153.1890502\ttotal: 1.43s\tremaining: 8.57s\n",
      "200:\tlearn: 120.4697874\ttotal: 2.83s\tremaining: 7.13s\n",
      "300:\tlearn: 98.0825585\ttotal: 4.25s\tremaining: 5.73s\n",
      "400:\tlearn: 82.4396398\ttotal: 5.92s\tremaining: 4.52s\n",
      "500:\tlearn: 69.0651868\ttotal: 7.44s\tremaining: 3.06s\n",
      "600:\tlearn: 58.2335012\ttotal: 8.89s\tremaining: 1.57s\n",
      "700:\tlearn: 49.7788435\ttotal: 10.3s\tremaining: 88.5ms\n",
      "706:\tlearn: 49.2857179\ttotal: 10.4s\tremaining: 0us\n",
      "0:\tlearn: 538.2044553\ttotal: 4.29ms\tremaining: 2.67s\n",
      "100:\tlearn: 349.9500877\ttotal: 351ms\tremaining: 1.81s\n",
      "200:\tlearn: 278.8908456\ttotal: 680ms\tremaining: 1.43s\n",
      "300:\tlearn: 231.8618444\ttotal: 1.02s\tremaining: 1.09s\n",
      "400:\tlearn: 199.3420179\ttotal: 1.35s\tremaining: 750ms\n",
      "500:\tlearn: 174.1264260\ttotal: 1.68s\tremaining: 410ms\n",
      "600:\tlearn: 155.4358281\ttotal: 2.02s\tremaining: 73.9ms\n",
      "622:\tlearn: 151.4913380\ttotal: 2.09s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "processed = process(train_df, test_df)\n",
    "\n",
    "\n",
    "train_processed = {\n",
    "    'df_normal': processed['train_df_normal_clean'],\n",
    "    'df_short_route': processed['train_df_short_route_clean'],\n",
    "    'df_outside': processed['train_df_outside_clean']\n",
    "}\n",
    "test_processed = {\n",
    "    'test_normal': processed['test_normal'],\n",
    "    'test_short_route': processed['test_short_route'],\n",
    "    'test_outside': processed['test_outside']\n",
    "}\n",
    "\n",
    "best_params = {\n",
    "    'normal': {'iterations': 935, 'learning_rate': 0.026969688839420358, 'depth': 9, 'l2_leaf_reg': 0.26599614070518346}, 'short': {'iterations': 707, 'learning_rate': 0.011882972946608549, 'depth': 10, 'l2_leaf_reg': 0.014346258174116461}, 'outside': {'iterations': 623, 'learning_rate': 0.04864367507269438, 'depth': 7, 'l2_leaf_reg': 2.0705930414149356}\n",
    "}\n",
    "\n",
    "models, feature_lists = build_models_with_best_params(train_processed, best_params)\n",
    "\n",
    "final_predictions = infer(models, train_processed, test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:10:07.762409Z",
     "iopub.status.busy": "2025-03-10T16:10:07.762056Z",
     "iopub.status.idle": "2025-03-10T16:10:09.025559Z",
     "shell.execute_reply": "2025-03-10T16:10:09.024410Z",
     "shell.execute_reply.started": "2025-03-10T16:10:07.762383Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for key, df in train_processed.items():\n",
    "    df.to_csv(f\"{key}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:10:09.029796Z",
     "iopub.status.busy": "2025-03-10T16:10:09.029468Z",
     "iopub.status.idle": "2025-03-10T16:10:09.050560Z",
     "shell.execute_reply": "2025-03-10T16:10:09.049600Z",
     "shell.execute_reply.started": "2025-03-10T16:10:09.029770Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission preview:\n",
      "   id         rta\n",
      "0   0   93.588947\n",
      "1   1   94.940226\n",
      "2   2  102.297535\n",
      "3   3   72.651790\n",
      "4   4   86.034883\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'id': final_predictions['Id'],  # ensure this column exists in your test data\n",
    "    'rta': final_predictions['predicted_rta']\n",
    "})\n",
    "\n",
    "# Clip any negative values to 0\n",
    "submission['rta'] = submission['rta'].clip(lower=0)\n",
    "\n",
    "submission.to_csv(\"submission_pake_3model_highest_ditambainmethodrta_tuned_asrama.csv\", index=False)\n",
    "print(\"Submission preview:\")\n",
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11198557,
     "sourceId": 94040,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
